import os
import json
import re
import datetime
from typing import Any, Dict, List

import streamlit as st
from google import genai
from google.genai import types

# ----------------------------
# Config & Client
# ----------------------------
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")

# 
FLASH_MODEL = os.getenv("FLASH_MODEL", "gemini-3-flash-preview")
PRO_MODEL   = os.getenv("PRO_MODEL",   "gemini-3-pro-preview")

if not GEMINI_API_KEY:
    st.error("Missing GEMINI_API_KEY. Please set it in your environment.")
    st.stop()

client = genai.Client(api_key=GEMINI_API_KEY)

# 专砖转 拽专转 专 驻拽 
FACT_CHECK_SITES = [
    "FakeReporter.net", "Irrelevant.org.il", "TheWhistle (Globes)", 
    "Snopes", "Bellingcat", "CheckYourFact", "FullFact.org", "Abu Ali Express"
]

# ----------------------------
# Utilities
# ----------------------------
def _clean_links(raw: str) -> List[str]:
    urls = re.findall(r"https?://[^\s)>\]]+", raw or "")
    out, seen = [], set()
    for u in urls:
        if u not in seen:
            seen.add(u)
            out.append(u)
    return out[:20]

def _safe_json_loads(s: str) -> Dict[str, Any]:
    s = (s or "").strip()
    if s.startswith("```"):
        s = re.sub(r"^```[a-zA-Z]*\s*", "", s)
        s = re.sub(r"\s*```$", "", s).strip()
    try:
        return json.loads(s)
    except json.JSONDecodeError:
        m = re.search(r"(\{.*\})", s, re.DOTALL)
        if m:
            try:
                return json.loads(m.group(1))
            except:
                pass
        return {"error": "Failed to parse JSON", "raw": s}

def _extract_grounding_urls(resp: Any) -> List[str]:
    urls = []
    try:
        if resp.candidates:
            gm = resp.candidates[0].grounding_metadata
            if gm and gm.grounding_chunks:
                for chunk in gm.grounding_chunks:
                    if chunk.web and chunk.web.uri:
                        urls.append(chunk.web.uri)
    except Exception:
        pass
    return list(dict.fromkeys(urls))

# ----------------------------
# Step 1: Source Discovery (Flash Model - HARD SIGNALS & OSINT)
# ----------------------------
def run_flash_source_discovery(user_news: str, links: List[str], images: List[bytes]) -> Dict[str, Any]:
    search_tool = types.Tool(google_search=types.GoogleSearch())
    
    current_date = datetime.datetime.now().strftime("%Y-%m-%d")

    # 驻专驻 砖专 注 转拽转 "住 注" (Hard Indicators)
    prompt = f"""
You are an Elite Military Intelligence Collector (OSINT) running on {FLASH_MODEL}.
Current Date: {current_date}.

YOUR MISSION: Validate the event and collect "Hard Signals" (Indicators & Warnings).
Do not just look for headlines. Look for LOGISTICS and PHYSICAL movements.

SEARCH STRATEGY (Force these queries):
1.  **Social Media**: Use `site:twitter.com` and `site:t.me` to find real-time reports.
2.  **Hard Indicators**:
    -   GPS Jamming reports (Waze/Maps anomalies).
    -   Hospital preparations (transfer to underground wards).
    -   Flight restrictions (NOTAMs).
    -   Reserve call-ups (Tzav 8).
    -   Embassy warnings / Evacuations.

OUTPUT FORMAT (STRICT JSON):
{{
  "event_summary": "Concise summary of the situation",
  "hard_indicators": {{
      "logistics_status": "Description of supply/hospital/transport status found",
      "military_movements": "Description of any troop/tank/plane movements reported",
      "civilian_impact": "GPS jamming, school cancellations, etc."
  }},
  "social_media_intel": {{
      "telegram_chatter": ["Specific claims from Telegram"],
      "twitter_signals": ["Specific claims from X"]
  }},
  "source_reliability": "High/Medium/Low based on cross-referencing",
  "contradictions": ["List if official news contradicts social media"],
  "known_hoax_check": {{
      "is_fake": boolean,
      "details": "Explanation if fake"
  }}
}}
"""

    parts = [types.Part(text=prompt), types.Part(text=f"Subject to Investigate: {user_news}\nLinks provided: {links}")]
    for img in images[:8]:
        parts.append(types.Part(inline_data=types.Blob(mime_type="image/png", data=img)))

    config = types.GenerateContentConfig(
        tools=[search_tool],
        temperature=0.0, # 驻住 爪专转转, 专拽 注转
        response_mime_type="application/json", 
    )

    try:
        resp = client.models.generate_content(
            model=FLASH_MODEL,
            contents=[types.Content(role="user", parts=parts)],
            config=config,
        )
        pkg = _safe_json_loads(resp.text)
        pkg["verified_links"] = _extract_grounding_urls(resp)
        return pkg
    except Exception as e:
        return {"error": f"Flash Model Error: {str(e)}", "verified_links": []}

# ----------------------------
# Step 2: Strategic Analysis (Pro Model - ACH METHODOLOGY)
# ----------------------------
def run_pro_strategic_analysis(pkg: Dict[str, Any]) -> str:
    system_instruction = "You are a Senior Intelligence Assessment Officer using the 'Analysis of Competing Hypotheses' (ACH) method."

    user_prompt = f"""
转 转 -Data Package  驻拽 " 注专转 .
转住住  专拽 注 注 砖住祝:
{json.dumps(pkg, ensure_ascii=False)}

注 爪注 转 砖 砖 "驻 住转专" (Devil's Advocate) 驻 拽注转 住转专转.

 " ( 拽驻 注 住专):

1. **住住 住 注 (Hard Signals Status)**:
    爪 转 住转 砖? (转 , 住 , 砖砖 GPS).   爪, 爪 转 专专.

2. **转 砖注专转 转专转 (ACH Analysis)**:
   - *砖注专 ' (住 ):*  转 ?
   - *砖注专 ' ( 驻住转/专注砖):*  转 ?
   - *专注:*  爪 拽 转专 专转?

3. **转 住专转  (The Probability Matrix)**:
   爪专 转 Markdown:
   |   | 住专转 (%) | 拽 注 (Evidence Based) | 专转  注专 |
   |---|---|---|---|
   |  (注 砖) | % | ... | ... |
   | 拽爪专 (3 砖) | % | ... | ... |
   |  (6 砖) | % | ... | ... |
   | 专 (砖) | % | ... | ... |

   * 专 拽注转 :*   住 住 (拽, 转 , 转砖转) - 住专转  转 转 转 ,   专专拽 专 .

4. **住拽 拽 转**: 砖专 转转 专专.

转 注专转 注转, 拽专 拽转.
"""
    try:
        resp = client.models.generate_content(
            model=PRO_MODEL,
            contents=[types.Content(role="user", parts=[types.Part(text=user_prompt)])],
            config=types.GenerateContentConfig(
                system_instruction=system_instruction,
                temperature=0.2
            ),
        )
        return resp.text
    except Exception as e:
        return f"Pro Model Error: {str(e)}"

# ----------------------------
# Streamlit Interface
# ----------------------------
st.set_page_config(page_title="Gemini 3 OSINT War Room", layout="wide", page_icon="")

st.markdown("""
<style>
    .stTextArea textarea { font-size: 16px !important; }
    .stAlert { direction: rtl; }
</style>
""", unsafe_allow_html=True)

st.title(" Gemini 3 Advanced OSINT & War Predictor")
st.caption(f"Engine: {FLASH_MODEL} (Collector) -> {PRO_MODEL} (Analyst) | Method: ACH & Hard Signals")

with st.sidebar:
    st.header("注专 住祝")
    st.info("注专转 住专拽转 驻 : \n- Twitter/X \n- Telegram Channels \n- Official Reports \n- Fact Checkers")
    st.divider()
    st.write("**拽专转 转:**", FACT_CHECK_SITES)

col1, col2 = st.columns([1, 1])

with col1:
    st.subheader(" 转 注")
    user_text = st.text_area("砖 拽专 (拽住 驻砖 / 砖注):", height=200, placeholder=":  专 注 转注转 转 专  爪驻...")
    user_links = st.text_area("拽砖专 住驻爪驻 (驻爪):", height=100)

with col2:
    st.subheader(" 专转 转")
    uploaded = st.file_uploader("注 爪 住/驻转:", type=["png", "jpg", "jpeg"], accept_multiple_files=True)
    if uploaded:
        st.success(f"{len(uploaded)} 拽爪 注 转")

if st.button(" 专抓 注专转 注 ", type="primary", use_container_width=True):
    if not user_text and not uploaded:
        st.error("  拽住  注转 转.")
    else:
        links = _clean_links(user_links)
        imgs = [f.read() for f in uploaded] if uploaded else []

        # 拽专 转
        with st.status("爪注  拽专 注...", expanded=True) as status:
            
            # 砖 1
            st.write(" **Flash:** 住专拽转 专砖转转, 转专 住 注 (GPS, 住拽)...")
            data_package = run_flash_source_discovery(user_text, links, imgs)
            
            if "error" in data_package and not data_package.get("verified_links"):
                status.update(label="砖 住祝", state="error")
                st.error(f"转拽: {data_package['error']}")
                st.stop()
            
            # 爪转 爪 
            inds = data_package.get("hard_indicators", {})
            st.markdown(f"""
            - **爪 住:** {len(inds.get('logistics_status', '')) > 5}
            - **砖 专/专:** {len(data_package.get('social_media_intel', {}).get('telegram_chatter', []))} 驻专
            """)

            # 砖 2
            st.write(" **Pro:** 爪注 转 砖注专转 转专转 (ACH) 砖 住转专转...")
            final_report = run_pro_strategic_analysis(data_package)
            
            status.update(label="注专转 爪 砖", state="complete")

        # 爪转 转爪转
        st.divider()
        
        # 专转 驻拽
        if data_package.get("known_hoax_check", {}).get("is_fake"):
            st.error(f" **专 砖转  (Fake News):** {data_package['known_hoax_check']['details']}")
        
        st.markdown("##  \" 注 住")
        st.markdown(final_report)

        # 专转
        with st.expander(" 转  砖 (JSON)"):
            st.json(data_package)
            
        with st.expander(" 拽专转 注 砖转"):
            for link in data_package.get("verified_links", []):
                st.markdown(f"- [{link}]({link})")
